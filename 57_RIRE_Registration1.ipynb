{"nbformat_minor": 0, "cells": [{"source": "<h1 align=\"center\">Introduction to SimpleITKv4 Registration</h1>\n\n\n<table width=\"100%\">\n<tr style=\"background-color: red;\"><td><font color=\"white\">SimpleITK conventions:</font></td></tr>\n<tr><td>\n<ul>\n<li>Dimensionality and pixel type of registered images is required to be the same (2D/2D or 3D/3D).</li>\n<li>Supported pixel types are sitkFloat32 and sitkFloat64 (use the SimpleITK <a href=\"http://www.itk.org/SimpleITKDoxygen/html/namespaceitk_1_1simple.html#af8c9d7cc96a299a05890e9c3db911885\">Cast()</a> function if your image's pixel type is something else).\n</ul>\n</td></tr>\n</table>\n\n\n## Registration Components \n\n<img src=\"ITKv4RegistrationComponentsDiagram.svg\" style=\"width:700px\"/><br><br>\n\nThere are many options for creating an instance of the registration framework, all of which are configured in SimpleITK via methods of the <a href=\"http://www.itk.org/SimpleITKDoxygen/html/classitk_1_1simple_1_1ImageRegistrationMethod.html\">ImageRegistrationMethod</a> class. This class encapsulates many of the components available in ITK for constructing a registration instance.\n\nCurrently, the available choices from the following groups of ITK components are:\n\n### Optimizers\n\nThe SimpleITK registration framework supports several optimizer types via the SetMetricAsX() methods, these include:\n\n<ul>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1ExhaustiveOptimizerv4.html\">Exhaustive</a>\n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1AmoebaOptimizerv4.html\">Nelder-Mead downhill simplex</a>, a.k.a. Amoeba.\n  </li>\n  <li>\n  Variations on gradient descent:\n  <ul>\n    <li>\n    <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1GradientDescentOptimizerv4Template.html\">GradientDescent</a>\n    </li>\n    <li>\n    <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1GradientDescentLineSearchOptimizerv4Template.html\">GradientDescentLineSearch</a>\n    </li>\n    <li>\n    <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1RegularStepGradientDescentOptimizerv4.html\">RegularStepGradientDescent</a>\n    </li>\n  </ul>\n  </li>\n  <li>\n    <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1ConjugateGradientLineSearchOptimizerv4Template.html\">ConjugateGradientLineSearch</a> \n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1LBFGSBOptimizerv4.html\">L-BFGS-B</a> (Limited memory Broyden,  Fletcher,Goldfarb,Shannon-Bound Constrained) - supports the use of simple constraints ($l\\leq x \\leq u$)  \n  </li>\n</ul>\n\n \n### Similarity metrics\n\nThe SimpleITK registration framework supports several metric types via the SetMetricAsX() methods, these include:\n\n<ul>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1MeanSquaresImageToImageMetricv4.html\">MeanSquares</a>\n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1DemonsImageToImageMetricv4.html\">Demons</a>\n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1CorrelationImageToImageMetricv4.html\">Correlation</a>\n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1ANTSNeighborhoodCorrelationImageToImageMetricv4.html\">ANTSNeighborhoodCorrelation</a>\n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1JointHistogramMutualInformationImageToImageMetricv4.html\">JointHistogramMutualInformation</a>\n  </li>\n  <li>\n  <a href=\"http://www.itk.org/Doxygen/html/classitk_1_1MattesMutualInformationImageToImageMetricv4.html\">MattesMutualInformation</a>\n  </li>\n</ul>\n\n\n### Interpolators\n\nThe SimpleITK registration framework supports several interpolators via the SetInterpolator() method, which receives one of\nthe <a href=\"http://www.itk.org/SimpleITKDoxygen/html/namespaceitk_1_1simple.html#a7cb1ef8bd02c669c02ea2f9f5aa374e5\">following enumerations</a>:\n<ul>\n<li> sitkNearestNeighbor </li>\n<li> sitkLinear </li>\n<li> sitkBSpline </li>\n<li> sitkGaussian </li>\n<li> sitkHammingWindowedSinc </li>\n<li> sitkCosineWindowedSinc </li>\n<li> sitkWelchWindowedSinc </li>\n<li> sitkLanczosWindowedSinc </li>\n<li> sitkBlackmanWindowedSinc </li>\n</ul>\n\n## Data -  Retrospective Image Registration Evaluation\n\nWe will be using part of the training data from the Retrospective Image Registration Evaluation (<a href=\"http://www.insight-journal.org/rire/\">RIRE</a>) project.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import SimpleITK as sitk\n\n    #utility method that either downloads data from the MIDAS repository or\n    #if already downloaded returns the file name for reading from disk (cached data)\nfrom downloaddata import fetch_midas_data as fdata\n\n    #always write output to a separate directory, we don't want to polute the source directory \nimport os\nOUTPUT_DIR = 'Output'", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "##Utility functions\nA number of utility callback functions for image display and for ploting the similarity metric during registration.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom IPython.html.widgets import interact, fixed\nfrom IPython.display import clear_output\n\n    #callback invoked by the interact ipython method for scrolling through the image stacks of\n    #the two images (moving and fixed)\ndef display_images(fixed_image_z, moving_image_z, fixed_npa, moving_npa):\n        #create a figure with two subplots and the specified size\n    plt.subplots(1,2,figsize=(10,8))\n        #draw the fixed image in the first subplot\n    plt.subplot(1,2,1)\n    plt.imshow(fixed_npa[fixed_image_z,:,:],cmap=plt.cm.Greys_r);\n    plt.title('fixed image')\n    plt.axis('off')\n        #draw the moving image in the second subplot\n    plt.subplot(1,2,2)\n    plt.imshow(moving_npa[moving_image_z,:,:],cmap=plt.cm.Greys_r);\n    plt.title('moving image')\n    plt.axis('off')\n\n    #callback invoked by the ipython interact method for scrolling and modifying the alpha blending\n    #of an image stack of two images that occupy the same physical space. \ndef display_images_with_alpha(image_z, alpha, fixed, moving):\n    img = (1.0 - alpha)*fixed[:,:,image_z] + alpha*moving[:,:,image_z] \n    plt.imshow(sitk.GetArrayFromImage(img),cmap=plt.cm.Greys_r);\n    plt.axis('off')\n    \n    \n    #callback invoked when the StartEvent happens, sets up our new data\ndef start_plot():\n    global metric_values, multires_iterations\n    \n    metric_values = []\n    multires_iterations = []\n\n    #callback invoked when the EndEvent happens, do cleanup of data and figure\ndef end_plot():\n    global metric_values, multires_iterations\n    \n    del metric_values\n    del multires_iterations\n        #close figure, we don't want to get a duplicate of the plot latter on\n    plt.close()\n\n    #callback invoked when the IterationEvent happens, update our data and display new figure    \ndef plot_values(registration_method):\n    global metric_values, multires_iterations\n    \n    metric_values.append(registration_method.GetMetricValue())                                       \n        #clear the output area (wait=True, to reduce flickering), and plot current data\n    clear_output(wait=True)\n        #plot the similarity metric values\n    plt.plot(metric_values, 'r')\n    plt.plot(multires_iterations, [metric_values[index] for index in multires_iterations], 'b*')\n    plt.xlabel('Iteration Number',fontsize=12)\n    plt.ylabel('Metric Value',fontsize=12)\n    plt.show()\n    \n    #callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the \n    #metric_values list. \ndef update_multires_iterations():\n    global metric_values, multires_iterations\n    multires_iterations.append(len(metric_values))        ", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "## Read images\n\nWe first read the images, casting the pixel type to that required for registration (Float32 or Float64) and look at them.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "fixed_image =  sitk.ReadImage(fdata(\"training_001_ct.mha\"), sitk.sitkFloat32)\nmoving_image = sitk.ReadImage(fdata(\"training_001_mr_T1.mha\"), sitk.sitkFloat32) \n\ninteract(display_images, fixed_image_z=(0,fixed_image.GetSize()[2]-1), moving_image_z=(0,moving_image.GetSize()[2]-1), fixed_npa = fixed(sitk.GetArrayFromImage(fixed_image)), moving_npa=fixed(sitk.GetArrayFromImage(moving_image)));", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "## Initial Alignment\n\nUse the CenteredTransformInitializer to align the centers of the two volumes and set the center of rotation to the center of the fixed image.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "initial_transform = sitk.CenteredTransformInitializer(fixed_image, \n                                                      moving_image, \n                                                      sitk.Euler3DTransform(), \n                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)\n\nmoving_resampled = sitk.Resample(moving_image, fixed_image, initial_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelIDValue())\n\ninteract(display_images_with_alpha, image_z=(0,fixed_image.GetSize()[2]), alpha=(0.0,1.0,0.05), fixed = fixed(fixed_image), moving=fixed(moving_resampled));", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "## Registration\n\nThe specific registration task at hand estimates a 3D rigid transformation between images of different modalities. There are multiple components from each group (optimizers, similarity metrics, interpolators) that are appropriate for the task. Note that each component selection requires setting some parameter values. We have made the following choices:\n\n<ul>\n<li>Similarity metric, mutual information (Mattes MI):\n<ul>\n  <li>Number of histogram bins, 50.</li>\n  <li>Sampling strategy, random.</li>\n  <li>Sampling percentage, 1%.</li>\n</ul>\n</li>\n<li>Interpolator, sitkLinear.</li>\n<li>Optimizer, gradient descent: \n<ul>\n  <li>Learning rate, step size along traversal direction in parameter space, 1.0 .</li>\n  <li>Number of iterations, maximal number of iterations, 100.</li>\n  <li>Convergence minimum value, value used for convergence checking in conjunction with the energy profile of the similarity metric that is estimated in the given window size, 1e-6.</li>\n  <li>Convergence window size, number of values of the similarity metric which are used to estimate the energy profile of the similarity metric, 10.</li>\n</ul>\n</li>\n</ul>\n\n\nPerform registration using the settings given above, and take advantage of the built in multi-resolution framework, use a three tier pyramid.  \n\nIn this example we plot the similarity metric's value during regisration. Note that the change of scales in the multi-resolution framework is readily visible.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "registration_method = sitk.ImageRegistrationMethod()\n\n    #similarity metric settings\nregistration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\nregistration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\nregistration_method.SetMetricSamplingPercentage(0.01)\n\nregistration_method.SetInterpolator(sitk.sitkLinear)\n\n    #optimizer settings\nregistration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100, convergenceMinimumValue=1e-6, convergenceWindowSize=10)\nregistration_method.SetOptimizerScalesFromPhysicalShift()\n\n    #setup for the multi-resolution framework            \nregistration_method.SetShrinkFactorsPerLevel(shrinkFactors = [4,2,1])\nregistration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2,1,0])\nregistration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n\n    #don't optimize in-place, we would possibly like to run this cell multiple times\nregistration_method.SetInitialTransform(initial_transform, inPlace=False)\n\n    #connect all of the observers so that we can perform plotting during registration\nregistration_method.AddCommand(sitk.sitkStartEvent, start_plot)\nregistration_method.AddCommand(sitk.sitkEndEvent, end_plot)\nregistration_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, update_multires_iterations) \nregistration_method.AddCommand(sitk.sitkIterationEvent, lambda: plot_values(registration_method))\n\nfinal_transform = registration_method.Execute(sitk.Cast(fixed_image, sitk.sitkFloat32), \n                                              sitk.Cast(moving_image, sitk.sitkFloat32))", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "## Post registration analysis", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "Query the registration method to see the metric value and the reason the optimization terminated. \n\nThe metric value allows us to compare multiple registration runs as there is a probabilistic aspect to our registration, we are using random sampling to estimate the similarity metric.\n\nAlways remember to query why the optimizer terminated. This will help you understand whether termination is too early, either due to thresholds being too tight, early termination due to small number of iterations - numberOfIterations, or too loose, early termination due to large value for minimal change in similarity measure - convergenceMinimumValue)    ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "print('Final metric value: {0}'.format(registration_method.GetMetricValue()))\nprint('Optimizer\\'s stopping condition, {0}'.format(registration_method.GetOptimizerStopConditionDescription()))", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "Now visually inspect the results.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "moving_resampled = sitk.Resample(moving_image, fixed_image, final_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelIDValue())\n\ninteract(display_images_with_alpha, image_z=(0,fixed_image.GetSize()[2]), alpha=(0.0,1.0,0.05), fixed = fixed(fixed_image), moving=fixed(moving_resampled));", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"source": "If we are satisfied with the results, save them to file.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "sitk.WriteImage(moving_resampled, os.path.join(OUTPUT_DIR, 'RIRE_training_001_mr_T1_resampled.mha'))\nsitk.WriteTransform(final_transform, os.path.join(OUTPUT_DIR, 'RIRE_training_001_CT_2_mr_T1.tfm'))", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}