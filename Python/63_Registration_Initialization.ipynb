{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Registration Initialization: We Have to Start Somewhere</h1>\n",
    "\n",
    "Initialization is a critical aspect of most registration algorithms, given that most algorithms are formulated as an iterative optimization problem.\n",
    "\n",
    "In many cases we perform initialization in an automatic manner by making assumptions with regard to the contents of the image and the imaging protocol. For instance, if we expect that images were acquired with the patient in a known orientation we can align the geometric centers of the two volumes or the center of mass of the image contents if the anatomy is not centered in the image (this is what we previously did in [this example](60_Registration_Introduction.ipynb)).\n",
    "\n",
    "When the orientation is not known, or is known but incorrect, this approach will not yield a reasonable initial estimate for the registration.\n",
    "\n",
    "When working with clinical images, the DICOM tags define the orientation and position of the anatomy in the volume. The tags of interest are:\n",
    "<ul>\n",
    "  <li> (0020|0032) Image Position (Patient) : coordinates of the the first transmitted voxel. </li>\n",
    "  <li>(0020|0037) Image Orientation (Patient): directions of first row and column in 3D space. </li>\n",
    "  <li>(0018|5100) Patient Position: Patient placement on the table \n",
    "  <ul>\n",
    "  <li> Head First Prone (HFP)</li>\n",
    "  <li> Head First Supine (HFS)</li>\n",
    "  <li> Head First Decubitus Right (HFDR)</li>\n",
    "  <li> Head First Decubitus Left (HFDL)</li>\n",
    "  <li> Feet First Prone (FFP)</li>\n",
    "  <li> Feet First Supine (FFS)</li>\n",
    "  <li> Feet First Decubitus Right (FFDR)</li>\n",
    "  <li> Feet First Decubitus Left (FFDL)</li>\n",
    "  </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "The patient position is manually entered by the CT/MR operator and thus can be erroneous (HFP instead of FFP will result in a $180^o$ orientation error).\n",
    "\n",
    "A heuristic, yet effective, solution is to use a sampling strategy of the parameter space. Note that this strategy is primarily useful in low dimensional parameter spaces (rigid or possibly affine transformations). \n",
    "\n",
    "In this notebook we illustrate how to sample the parameter space in a fixed pattern. We then initialize the registration with the parameters that correspond to the best similarity metric value obtained by our sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "# If the environment variable SIMPLE_ITK_MEMORY_CONSTRAINED_ENVIRONMENT is set, this will override the ReadImage\n",
    "# function so that it also resamples the image to a smaller size (testing environment is memory constrained).\n",
    "%run setup_for_testing\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "%run update_path_to_download_script\n",
    "from downloaddata import fetch_data as fdata\n",
    "\n",
    "import registration_callbacks as rc\n",
    "import registration_utilities as ru\n",
    "\n",
    "# Always write output to a separate directory, we don't want to pollute the source directory. \n",
    "OUTPUT_DIR = 'Output'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# This is the registration configuration which we use in all cases. The only parameter that we vary \n",
    "# is the initial_transform. \n",
    "def multires_registration(fixed_image, moving_image, initial_transform):\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100, estimateLearningRate=registration_method.Once)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift() \n",
    "    registration_method.SetInitialTransform(initial_transform)\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors = [4,2,1])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas = [2,1,0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    registration_method.AddCommand(sitk.sitkStartEvent, rc.metric_start_plot)\n",
    "    registration_method.AddCommand(sitk.sitkEndEvent, rc.metric_end_plot)\n",
    "    registration_method.AddCommand(sitk.sitkMultiResolutionIterationEvent, rc.metric_update_multires_iterations) \n",
    "    registration_method.AddCommand(sitk.sitkIterationEvent, lambda: rc.metric_plot_values(registration_method))\n",
    "\n",
    "    final_transform = registration_method.Execute(fixed_image, moving_image)\n",
    "    print('Final metric value: {0}'.format(registration_method.GetMetricValue()))\n",
    "    print('Optimizer\\'s stopping condition, {0}'.format(registration_method.GetOptimizerStopConditionDescription()))\n",
    "    return final_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_directory = os.path.dirname(fdata(\"CIRS057A_MR_CT_DICOM/readme.txt\"))\n",
    "\n",
    "fixed_series_ID = \"1.2.840.113619.2.290.3.3233817346.783.1399004564.515\"\n",
    "moving_series_ID = \"1.3.12.2.1107.5.2.18.41548.30000014030519285935000000933\"\n",
    "\n",
    "reader = sitk.ImageSeriesReader()\n",
    "fixed_image = sitk.ReadImage(reader.GetGDCMSeriesFileNames(data_directory, fixed_series_ID), sitk.sitkFloat32)\n",
    "moving_image = sitk.ReadImage(reader.GetGDCMSeriesFileNames(data_directory, moving_series_ID), sitk.sitkFloat32)\n",
    "\n",
    "# To provide a reasonable display we need to window/level the images. By default we could have used the intensity\n",
    "# ranges found in the images [SimpleITK's StatisticsImageFilter], but these are not the best values for viewing.\n",
    "# Using an external viewer we identified the following settings.\n",
    "fixed_intensity_range = (-1183,544)\n",
    "moving_intensity_range = (0,355)\n",
    "\n",
    "interact(lambda image1_z, image2_z, image1, image2,:ru.display_scalar_images(image1_z, image2_z, image1, image2, \n",
    "                                                                             fixed_intensity_range,\n",
    "                                                                             moving_intensity_range,\n",
    "                                                                             'fixed image',\n",
    "                                                                             'moving image'), \n",
    "         image1_z=(0,fixed_image.GetSize()[2]-1), \n",
    "         image2_z=(0,moving_image.GetSize()[2]-1), \n",
    "         image1 = fixed(fixed_image), \n",
    "         image2=fixed(moving_image));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrarily rotate the moving image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rotation_x = 0.0\n",
    "rotation_z = 0.0\n",
    "\n",
    "def modify_rotation(rx_in_degrees, rz_in_degrees):\n",
    "    global rotation_x, rotation_z\n",
    "    \n",
    "    rotation_x = np.radians(rx_in_degrees)\n",
    "    rotation_z = np.radians(rz_in_degrees)\n",
    "    \n",
    "interact(modify_rotation, rx_in_degrees=(0.0,180.0,5.0), rz_in_degrees=(-90.0,180.0,5.0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resample = sitk.ResampleImageFilter()\n",
    "resample.SetReferenceImage(moving_image)\n",
    "resample.SetInterpolator(sitk.sitkLinear)\n",
    "# Rotate around the physical center of the image. \n",
    "rotation_center = moving_image.TransformContinuousIndexToPhysicalPoint([(index-1)/2.0 for index in moving_image.GetSize()])\n",
    "transform = sitk.Euler3DTransform(rotation_center, rotation_x, 0, rotation_z, (0,0,0))\n",
    "resample.SetTransform(transform)\n",
    "modified_moving_image = resample.Execute(moving_image)\n",
    "\n",
    "interact(lambda image1_z, image2_z, image1, image2,:ru.display_scalar_images(image1_z, image2_z, image1, image2, \n",
    "                                                                             moving_intensity_range,\n",
    "                                                                             moving_intensity_range, 'original', 'rotated'), \n",
    "         image1_z=(0,moving_image.GetSize()[2]-1), \n",
    "         image2_z=(0,modified_moving_image.GetSize()[2]-1), \n",
    "         image1 = fixed(moving_image), \n",
    "         image2=fixed(modified_moving_image));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register using standard initialization  (assumes orientation is similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_transform = sitk.CenteredTransformInitializer(fixed_image, \n",
    "                                                      modified_moving_image, \n",
    "                                                      sitk.Euler3DTransform(), \n",
    "                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "\n",
    "final_transform = multires_registration(fixed_image, modified_moving_image, initial_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually evaluate our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moving_resampled = sitk.Resample(modified_moving_image, fixed_image, final_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelID())\n",
    "\n",
    "interact(ru.display_images_with_alpha, image_z=(0,fixed_image.GetSize()[2]), alpha=(0.0,1.0,0.05), \n",
    "         image1 = fixed(sitk.IntensityWindowing(fixed_image, fixed_intensity_range[0], fixed_intensity_range[1])), \n",
    "         image2=fixed(sitk.IntensityWindowing(moving_resampled, moving_intensity_range[0], moving_intensity_range[1])));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register using heuristic initialization approach (using multiple orientations)\n",
    "\n",
    "As we want to account for significant orientation differences due to erroneous patient position (HFS...) we evaluate the similarity measure at locations corresponding to the various orientation differences. This can be done in two ways which will be illustrated below:\n",
    "<ul>\n",
    "<li>Use the ImageRegistrationMethod.MetricEvaluate() method.</li>\n",
    "<li>Use the Exhaustive optimizer.\n",
    "</ul>\n",
    "\n",
    "The former approach is more computationally intensive as it constructs and configures a metric object each time it is invoked. It is therefore more appropriate for use if the set of parameter values we want to evaluate are not on a rectilinear grid in the parameter space. The latter approach is appropriate if the set of parameter values are on a rectilinear grid, in which case the approach is more computationally efficient.\n",
    "\n",
    "In both cases we use the CenteredTransformInitializer to obtain the initial translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MetricEvaluate\n",
    "\n",
    "To use the MetricEvaluate method we create a ImageRegistrationMethod, set its metric and interpolator. We then iterate over all parameter settings, set the initial transform and evaluate the metric. The minimal similarity measure value corresponds to the best parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary with all the orientations we will try. We omit the identity (x=0, y=0, z=0) as we always use it. This\n",
    "# set of rotations is arbitrary. For a complete grid coverage we would naively have 64 entries \n",
    "# (0, pi/2, pi, 1.5pi for each angle), but we know better, there are only 24 unique rotation matrices defined by\n",
    "# these parameter value combinations.\n",
    "all_orientations = {'x=0, y=0, z=90': (0.0,0.0,np.pi/2.0),\n",
    "                    'x=0, y=0, z=-90': (0.0,0.0,-np.pi),\n",
    "                    'x=0, y=0, z=180': (0.0,0.0,np.pi),\n",
    "                    'x=180, y=0, z=0': (np.pi,0.0,0.0),\n",
    "                    'x=180, y=0, z=90': (np.pi,0.0,np.pi/2.0),\n",
    "                    'x=180, y=0, z=-90': (np.pi,0.0,-np.pi/2.0),\n",
    "                    'x=180, y=0, z=180': (np.pi,0.0,np.pi)}    \n",
    "\n",
    "# Registration framework setup.\n",
    "registration_method = sitk.ImageRegistrationMethod()\n",
    "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "registration_method.SetMetricSamplingPercentage(0.01)\n",
    "registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "# Evaluate the similarity metric using the eight possible orientations, translation remains the same for all.\n",
    "initial_transform = sitk.Euler3DTransform(sitk.CenteredTransformInitializer(fixed_image, \n",
    "                                                                            modified_moving_image, \n",
    "                                                                            sitk.Euler3DTransform(), \n",
    "                                                                            sitk.CenteredTransformInitializerFilter.GEOMETRY))\n",
    "registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "best_orientation = (0.0,0.0,0.0)\n",
    "best_similarity_value = registration_method.MetricEvaluate(fixed_image, modified_moving_image)\n",
    "\n",
    "# Iterate over all other rotation parameter settings. \n",
    "for key, orientation in all_orientations.items():\n",
    "    initial_transform.SetRotation(*orientation)\n",
    "    registration_method.SetInitialTransform(initial_transform)\n",
    "    current_similarity_value = registration_method.MetricEvaluate(fixed_image, modified_moving_image)\n",
    "    if current_similarity_value < best_similarity_value:\n",
    "        best_similarity_value = current_similarity_value\n",
    "        best_orientation = orientation\n",
    "print('best orientation is: ' + str(best_orientation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why loop if you can process in parallel\n",
    "As the metric evaluations are independent of each other, we can easily replace looping with parallelization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from functools import partial\n",
    "\n",
    "# This function evaluates the metric value in a thread safe manner\n",
    "def evaluate_metric(current_rotation, tx, f_image, m_image):\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "    current_transform = sitk.Euler3DTransform(tx)\n",
    "    current_transform.SetRotation(*current_rotation)\n",
    "    registration_method.SetInitialTransform(current_transform)\n",
    "    res = registration_method.MetricEvaluate(f_image, m_image)\n",
    "    return res\n",
    "\n",
    "p = ThreadPool(9)\n",
    "orientations_list = [(0,0,0)] + list(all_orientations.values())\n",
    "all_metric_values = p.map(partial(evaluate_metric, \n",
    "                                  tx = initial_transform, \n",
    "                                  f_image = fixed_image,\n",
    "                                  m_image = modified_moving_image),\n",
    "                          orientations_list)\n",
    "best_orientation = orientations_list[np.argmin(all_metric_values)]\n",
    "print('best orientation is: ' + str(best_orientation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_transform.SetRotation(*best_orientation)\n",
    "final_transform = multires_registration(fixed_image, modified_moving_image, initial_transform)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually evaluate our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moving_resampled = sitk.Resample(modified_moving_image, fixed_image, final_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelID())\n",
    "\n",
    "interact(ru.display_images_with_alpha, image_z=(0,fixed_image.GetSize()[2]), alpha=(0.0,1.0,0.05), \n",
    "         image1 = fixed(sitk.IntensityWindowing(fixed_image, fixed_intensity_range[0], fixed_intensity_range[1])), \n",
    "         image2=fixed(sitk.IntensityWindowing(moving_resampled, moving_intensity_range[0], moving_intensity_range[1])));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive optimizer\n",
    "\n",
    "The exhaustive optimizer evaluates the similarity measure using a grid overlaid on the parameter space.\n",
    "The grid is centered on the parameter values set by the SetInitialTransform, and the location of its vertices are determined by the <b>numberOfSteps</b>, <b>stepLength</b> and <b>optimizer scales</b>. To quote the documentation of this class: \"a side of the region is stepLength*(2*numberOfSteps[d]+1)*scaling[d].\"\n",
    "\n",
    "Using this approach we have superfluous evaluations (15 evaluations corresponding to 3 values for rotations around the x axis and five for rotation around the z axis, as compared to the 8 evaluations using the MetricEvaluate method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_transform = sitk.CenteredTransformInitializer(fixed_image, \n",
    "                                                      modified_moving_image, \n",
    "                                                      sitk.Euler3DTransform(), \n",
    "                                                      sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "registration_method = sitk.ImageRegistrationMethod()\n",
    "registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "registration_method.SetMetricSamplingPercentage(0.01)\n",
    "registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "# The order of parameters for the Euler3DTransform is [angle_x, angle_y, angle_z, t_x, t_y, t_z]. The parameter \n",
    "# sampling grid is centered on the initial_transform parameter values, that are all zero for the rotations. Given\n",
    "# the number of steps and their length and optimizer scales we have:\n",
    "# angle_x = -pi, 0, pi\n",
    "# angle_y = 0\n",
    "# angle_z = -pi, -pi/2, 0, pi/2, pi\n",
    "registration_method.SetOptimizerAsExhaustive(numberOfSteps=[1,0,2,0,0,0], stepLength = np.pi)\n",
    "registration_method.SetOptimizerScales([1,1,0.5,1,1,1])\n",
    "\n",
    "#Perform the registration in-place so that the initial_transform is modified.\n",
    "registration_method.SetInitialTransform(initial_transform, inPlace=True)\n",
    "registration_method.Execute(fixed_image, modified_moving_image)\n",
    "\n",
    "final_transform = multires_registration(fixed_image, modified_moving_image, initial_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually evaluate our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moving_resampled = sitk.Resample(modified_moving_image, fixed_image, final_transform, sitk.sitkLinear, 0.0, moving_image.GetPixelID())\n",
    "\n",
    "interact(ru.display_images_with_alpha, image_z=(0,fixed_image.GetSize()[2]), alpha=(0.0,1.0,0.05), \n",
    "         image1 = fixed(sitk.IntensityWindowing(fixed_image, fixed_intensity_range[0], fixed_intensity_range[1])), \n",
    "         image2=fixed(sitk.IntensityWindowing(moving_resampled, moving_intensity_range[0], moving_intensity_range[1])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
